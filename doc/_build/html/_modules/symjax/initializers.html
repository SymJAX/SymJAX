
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>symjax.initializers &#8212; symjax 0.0.1 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for symjax.initializers</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span>


<span class="k">def</span> <span class="nf">constant</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

<div class="viewcode-block" id="uniform"><a class="viewcode-back" href="../../modules/initializers.html#symjax.initializers.uniform">[docs]</a><span class="k">def</span> <span class="nf">uniform</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample initial weights from the uniform distribution.</span>
<span class="sd">    Parameters are sampled from U(a, b).</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    range : float or tuple</span>
<span class="sd">        When std is None then range determines a, b. If range is a float the</span>
<span class="sd">        weights are sampled from U(-range, range). If range is a tuple the</span>
<span class="sd">        weights are sampled from U(range[0], range[1]).</span>
<span class="sd">    std : float or None</span>
<span class="sd">        If std is a float then the weights are sampled from</span>
<span class="sd">        U(mean - numpy.sqrt(3) * std, mean + numpy.sqrt(3) * std).</span>
<span class="sd">    mean : float</span>
<span class="sd">        see std for description.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="nb">range</span><span class="p">,</span> <span class="s1">&#39;__len__&#39;</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="nb">range</span>  <span class="c1"># range is a tuple</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="nb">range</span><span class="p">,</span> <span class="nb">range</span>  <span class="c1"># range is a number</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span></div>

<div class="viewcode-block" id="normal"><a class="viewcode-back" href="../../modules/initializers.html#symjax.initializers.normal">[docs]</a><span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample initial weights from the Gaussian distribution.</span>
<span class="sd">    Initial weight parameters are sampled from N(mean, std).</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    std : float</span>
<span class="sd">        Std of initial parameters.</span>
<span class="sd">    mean : float</span>
<span class="sd">        Mean of initial parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="n">std</span> <span class="o">+</span> <span class="n">mean</span></div>


<span class="k">def</span> <span class="nf">orthogonal</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
     <span class="n">flat_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
     <span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">flat_shape</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
     <span class="n">u</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
     <span class="c1"># pick the one with the correct shape</span>
     <span class="n">q</span> <span class="o">=</span> <span class="n">u</span> <span class="k">if</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">flat_shape</span> <span class="k">else</span> <span class="n">v</span>
     <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">gain</span> <span class="o">*</span> <span class="n">q</span>


<div class="viewcode-block" id="glorot"><a class="viewcode-back" href="../../modules/initializers.html#symjax.initializers.glorot">[docs]</a><span class="k">def</span> <span class="nf">glorot</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">distribution</span><span class="o">=</span><span class="n">normal</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Glorot weight initialization.</span>
<span class="sd">    This is also known as Xavier initialization [1]_.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    initializer : lasagne.init.Initializer</span>
<span class="sd">        Initializer used to sample the weights, must accept `std` in its</span>
<span class="sd">        constructor to sample from a distribution with a given standard</span>
<span class="sd">        deviation.</span>
<span class="sd">    gain : float or &#39;relu&#39;</span>
<span class="sd">        Scaling factor for the weights. Set this to ``1.0`` for linear and</span>
<span class="sd">        sigmoid units, to &#39;relu&#39; or ``sqrt(2)`` for rectified linear units, and</span>
<span class="sd">        to ``sqrt(2/(1+alpha**2))`` for leaky rectified linear units with</span>
<span class="sd">        leakiness ``alpha``. Other transfer functions may need different</span>
<span class="sd">        factors.</span>
<span class="sd">    c01b : bool</span>
<span class="sd">        For a :class:`lasagne.layers.cuda_convnet.Conv2DCCLayer` constructed</span>
<span class="sd">        with ``dimshuffle=False``, `c01b` must be set to ``True`` to compute</span>
<span class="sd">        the correct fan-in and fan-out.</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Xavier Glorot and Yoshua Bengio (2010):</span>
<span class="sd">           Understanding the difficulty of training deep feedforward neural</span>
<span class="sd">           networks. International conference on artificial intelligence and</span>
<span class="sd">           statistics.</span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For a :class:`DenseLayer &lt;lasagne.layers.DenseLayer&gt;`, if ``gain=&#39;relu&#39;``</span>
<span class="sd">    and ``initializer=Uniform``, the weights are initialized as</span>
<span class="sd">    .. math::</span>
<span class="sd">       a &amp;= \\sqrt{\\frac{12}{fan_{in}+fan_{out}}}\\\\</span>
<span class="sd">       W &amp;\sim U[-a, a]</span>
<span class="sd">    If ``gain=1`` and ``initializer=Normal``, the weights are initialized as</span>
<span class="sd">    .. math::</span>
<span class="sd">       \\sigma &amp;= \\sqrt{\\frac{2}{fan_{in}+fan_{out}}}\\\\</span>
<span class="sd">       W &amp;\sim N(0, \\sigma)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                     <span class="s2">&quot;This initializer only works with shapes of length &gt;= 2&quot;</span><span class="p">)</span>

    <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">((</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">)</span> <span class="o">*</span> <span class="n">receptive_field_size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">distribution</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span></div>


<div class="viewcode-block" id="he"><a class="viewcode-back" href="../../modules/initializers.html#symjax.initializers.he">[docs]</a><span class="k">def</span> <span class="nf">he</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">distribution</span><span class="o">=</span><span class="n">normal</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;He weight initialization.</span>
<span class="sd">    Weights are initialized with a standard deviation of</span>
<span class="sd">    :math:`\\sigma = gain \\sqrt{\\frac{1}{fan_{in}}}` [1]_.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    initializer : lasagne.init.Initializer</span>
<span class="sd">        Initializer used to sample the weights, must accept `std` in its</span>
<span class="sd">        constructor to sample from a distribution with a given standard</span>
<span class="sd">        deviation.</span>
<span class="sd">    gain : float or &#39;relu&#39;</span>
<span class="sd">        Scaling factor for the weights. Set this to ``1.0`` for linear and</span>
<span class="sd">        sigmoid units, to &#39;relu&#39; or ``sqrt(2)`` for rectified linear units, and</span>
<span class="sd">        to ``sqrt(2/(1+alpha**2))`` for leaky rectified linear units with</span>
<span class="sd">        leakiness ``alpha``. Other transfer functions may need different</span>
<span class="sd">        factors.</span>
<span class="sd">    c01b : bool</span>
<span class="sd">        For a :class:`lasagne.layers.cuda_convnet.Conv2DCCLayer` constructed</span>
<span class="sd">        with ``dimshuffle=False``, `c01b` must be set to ``True`` to compute</span>
<span class="sd">        the correct fan-in and fan-out.</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Kaiming He et al. (2015):</span>
<span class="sd">           Delving deep into rectifiers: Surpassing human-level performance on</span>
<span class="sd">           imagenet classification. arXiv preprint arXiv:1502.01852.</span>
<span class="sd">    See Also</span>
<span class="sd">    ----------</span>
<span class="sd">    HeNormal  : Shortcut with Gaussian initializer.</span>
<span class="sd">    HeUniform : Shortcut with uniform initializer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">fan_in</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span></div>





</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">symjax</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules/symjax.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/pdfs.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor.pdfs</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor.signal</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/random.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor.random</span></code></a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules/datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.datasets</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/initializers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.initializers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/layers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.layers</span></code></a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Randall Balestriero.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>